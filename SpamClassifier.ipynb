{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03d1b413"
      },
      "source": [
        "# Task\n",
        "Fine-tune a BERT model for spam classification using the dataset from \"/content/spam_dataset_1000.csv\". The model should have a classifier with two final states: \"spam\" and \"not spam\". Use the following training configuration: learning rate of 2e-5 with linear decay, batch size of 16, 35 epochs with early stopping, and the AdamW optimizer with weight decay. Employ cross-entropy loss and evaluate the model using Accuracy, Precision, Recall, F1-Score, and AUC-ROC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afdc7a1b"
      },
      "source": [
        "## Load and preprocess the data\n",
        "\n",
        "### Subtask:\n",
        "Load the data from the provided CSV file, then prepare it for BERT input by tokenizing and encoding the text data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a4949c0"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the data from the CSV file into a pandas DataFrame and display the first few rows and information to understand its structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea02282a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/spam_dataset_1000.csv')\n",
        "display(df.head())\n",
        "display(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b23bd68f"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize a BERT tokenizer and tokenize the text data. The labels are already in a numerical format (0 and 1), which is suitable for the task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ab59be3"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "tokenized_texts = tokenizer(\n",
        "    list(df['text']),\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "labels = df['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45c07e52"
      },
      "source": [
        "## Split the data\n",
        "\n",
        "### Subtask:\n",
        "Split the preprocessed data into training and validation sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a9273e2"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the tokenized data and labels into training and validation sets using train_test_split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d36bf923"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_ids = tokenized_texts['input_ids']\n",
        "attention_masks = tokenized_texts['attention_mask']\n",
        "\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
        "    input_ids, labels, random_state=42, test_size=0.20\n",
        ")\n",
        "\n",
        "train_masks, val_masks, _, _ = train_test_split(\n",
        "    attention_masks, labels, random_state=42, test_size=0.20\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6272ecf"
      },
      "source": [
        "## Load the pre-trained bert model\n",
        "\n",
        "### Subtask:\n",
        "Load a pre-trained BERT model and add a classification layer on top for binary classification (spam/not spam).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ebc73b"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary class and load the pre-trained BERT model with a classification layer for binary classification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd7a3f36"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59393703"
      },
      "source": [
        "## Define training parameters\n",
        "\n",
        "### Subtask:\n",
        "Set up the optimizer, learning rate scheduler, and loss function based on the specified configurations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5d3fb2d"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize the optimizer and learning rate scheduler based on the specified configurations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5ae1482"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "epochs = 35\n",
        "batch_size = 16\n",
        "total_steps = len(train_inputs) // batch_size * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c21f9b4f"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "### Subtask:\n",
        "Train the model on the training data, including early stopping based on validation performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4754b3e2"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the training and validation data into PyTorch tensors, create TensorDataset and DataLoader objects, and implement the training loop with early stopping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "516da63f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import time\n",
        "import os\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "early_stop_epochs = 5\n",
        "best_model_path = \"best_model.pth\"\n",
        "\n",
        "for epoch_i in range(epochs):\n",
        "    print(f'======== Epoch {epoch_i + 1} / {epochs} ========')\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    training_time = time.time() - t0\n",
        "\n",
        "    print(f\"  Average training loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  Training epoch time: {training_time:.2f}s\")\n",
        "\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "    validation_time = time.time() - t0\n",
        "\n",
        "    print(f\"  Average validation loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"  Validation epoch time: {validation_time:.2f}s\")\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
        "    labels_flat = true_labels.flatten()\n",
        "\n",
        "    accuracy = accuracy_score(labels_flat, preds_flat)\n",
        "    precision = precision_score(labels_flat, preds_flat)\n",
        "    recall = recall_score(labels_flat, preds_flat)\n",
        "    f1 = f1_score(labels_flat, preds_flat)\n",
        "    auc_roc = roc_auc_score(labels_flat, predictions[:, 1])\n",
        "\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall: {recall:.4f}\")\n",
        "    print(f\"  F1-Score: {f1:.4f}\")\n",
        "    print(f\"  AUC-ROC: {auc_roc:.4f}\")\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(\"  Validation loss improved. Saving model.\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"  Validation loss did not improve for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "    if epochs_no_improve >= early_stop_epochs:\n",
        "        print(f\"  Early stopping triggered after {early_stop_epochs} epochs without improvement.\")\n",
        "        break\n",
        "\n",
        "print(\"\\nTraining complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5acce68b"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model on the validation set using the specified metrics (Accuracy, Precision, Recall, F1-Score, and AUC-ROC).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e73caa4"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the trained model on the validation set using the specified metrics. The previous code block already performed the evaluation during training. The metrics are already calculated and stored in the variables `accuracy`, `precision`, `recall`, `f1`, and `auc_roc`. I will print these metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2b22264"
      },
      "outputs": [],
      "source": [
        "print(\"Final Evaluation Metrics on Validation Set:\")\n",
        "print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall: {recall:.4f}\")\n",
        "print(f\"  F1-Score: {f1:.4f}\")\n",
        "print(f\"  AUC-ROC: {auc_roc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d371d49"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The dataset contains 1000 entries with two columns: 'text' and 'label'.\n",
        "*   The data was successfully preprocessed, tokenized, and split into training (80%) and validation (20%) sets.\n",
        "*   A `BertForSequenceClassification` model pre-trained on 'bert-base-uncased' was loaded with a 2-label classification head.\n",
        "*   The model was trained for 35 epochs with a batch size of 16, using the AdamW optimizer (lr=2e-5, weight\\_decay=0.01) and a linear learning rate scheduler.\n",
        "*   Cross-entropy loss was used for training, handled internally by the model.\n",
        "*   Early stopping was implemented with a patience of 5 epochs based on validation loss.\n",
        "*   The model achieved perfect scores (1.0000) on all validation metrics (Accuracy, Precision, Recall, F1-Score, and AUC-ROC) from epoch 2 onwards.\n",
        "*   The training process converged quickly, and early stopping was likely triggered due to the perfect validation performance.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Given the perfect scores on the validation set, the model may be overfitting to this specific dataset. Further evaluation on a separate, unseen test set is recommended to confirm its generalization performance.\n",
        "*   Consider training on a larger and more diverse spam dataset to build a more robust and generalizable spam classification model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9ee1c3"
      },
      "source": [
        "## Load and preprocess the data\n",
        "\n",
        "### Subtask:\n",
        "Load the data from the provided CSV file, then prepare it for BERT input by tokenizing and encoding the text data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2aa5730"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the data from the CSV file into a pandas DataFrame and display the first few rows and information to understand its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c309d62"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/spam.csv', encoding='latin-1') # Added encoding based on common spam datasets\n",
        "# Drop the extra columns\n",
        "df = df[['v1', 'v2']]\n",
        "# Rename columns for clarity\n",
        "df.columns = ['label', 'text']\n",
        "# Convert 'ham' to 0 and 'spam' to 1\n",
        "df['label'] = df['label'].apply(lambda x: 1 if x == 'spam' else 0)\n",
        "\n",
        "display(df.head())\n",
        "display(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9deaf04e"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize a BERT tokenizer and tokenize the text data. The labels are already in a numerical format (0 and 1), which is suitable for the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10b5f7bc"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "tokenized_texts = tokenizer(\n",
        "    list(df['text']),\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "labels = df['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c854aec"
      },
      "source": [
        "## Split the data\n",
        "\n",
        "### Subtask:\n",
        "Split the preprocessed data into training and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d07596de"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the tokenized data and labels into training and validation sets using train_test_split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56e7b562"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_ids = tokenized_texts['input_ids']\n",
        "attention_masks = tokenized_texts['attention_mask']\n",
        "\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
        "    input_ids, labels, random_state=42, test_size=0.20\n",
        ")\n",
        "\n",
        "train_masks, val_masks, _, _ = train_test_split(\n",
        "    attention_masks, labels, random_state=42, test_size=0.20\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d3d5310"
      },
      "source": [
        "## Load the pre-trained bert model\n",
        "\n",
        "### Subtask:\n",
        "Load a pre-trained BERT model and add a classification layer on top for binary classification (spam/not spam)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f160a890"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary class and load the pre-trained BERT model with a classification layer for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deb2898c"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a41410ba"
      },
      "source": [
        "## Define training parameters\n",
        "\n",
        "### Subtask:\n",
        "Set up the optimizer, learning rate scheduler, and loss function based on the specified configurations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c69078b"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize the optimizer and learning rate scheduler based on the specified configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0a05cd0"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "epochs = 35\n",
        "batch_size = 16\n",
        "total_steps = len(train_inputs) // batch_size * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c417102"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "### Subtask:\n",
        "Train the model on the training data, including early stopping based on validation performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b67588c"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the training and validation data into PyTorch tensors, create TensorDataset and DataLoader objects, and implement the training loop with early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "554f0267"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import time\n",
        "import os\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "early_stop_epochs = 5\n",
        "best_model_path = \"best_model.pth\"\n",
        "\n",
        "for epoch_i in range(epochs):\n",
        "    print(f'======== Epoch {epoch_i + 1} / {epochs} ========')\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    training_time = time.time() - t0\n",
        "\n",
        "    print(f\"  Average training loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  Training epoch time: {training_time:.2f}s\")\n",
        "\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "    validation_time = time.time() - t0\n",
        "\n",
        "    print(f\"  Average validation loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"  Validation epoch time: {validation_time:.2f}s\")\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "    preds_flat = np.argmax(predictions, axis=1).flatten()\n",
        "    labels_flat = true_labels.flatten()\n",
        "\n",
        "    accuracy = accuracy_score(labels_flat, preds_flat)\n",
        "    precision = precision_score(labels_flat, preds_flat)\n",
        "    recall = recall_score(labels_flat, preds_flat)\n",
        "    f1 = f1_score(labels_flat, preds_flat)\n",
        "    auc_roc = roc_auc_score(labels_flat, predictions[:, 1])\n",
        "\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall: {recall:.4f}\")\n",
        "    print(f\"  F1-Score: {f1:.4f}\")\n",
        "    print(f\"  AUC-ROC: {auc_roc:.4f}\")\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(\"  Validation loss improved. Saving model.\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"  Validation loss did not improve for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "    if epochs_no_improve >= early_stop_epochs:\n",
        "        print(f\"  Early stopping triggered after {early_stop_epochs} epochs without improvement.\")\n",
        "        break\n",
        "\n",
        "print(\"\\nTraining complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db721195"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model on the validation set using the specified metrics (Accuracy, Precision, Recall, F1-Score, and AUC-ROC)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1001f8b7"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the trained model on the validation set using the specified metrics. The previous code block already performed the evaluation during training. The metrics are already calculated and stored in the variables `accuracy`, `precision`, `recall`, `f1`, and `auc_roc`. I will print these metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a48f3f8"
      },
      "outputs": [],
      "source": [
        "print(\"Final Evaluation Metrics on Validation Set:\")\n",
        "print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall: {recall:.4f}\")\n",
        "print(f\"  F1-Score: {f1:.4f}\")\n",
        "print(f\"  AUC-ROC: {auc_roc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "007c3ac9"
      },
      "source": [
        "## Visualize the results\n",
        "\n",
        "### Subtask:\n",
        "Visualize the model evaluation metrics and the distribution of spam and ham in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a799aac2"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a bar plot to visualize the distribution of 'spam' and 'ham' in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d06a973b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize the distribution of spam and non-spam\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title('Distribution of Spam and Non-Spam')\n",
        "plt.xticks([0, 1], ['Not Spam', 'Spam'])\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be835b22"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a bar chart to visualize the evaluation metrics (Accuracy, Precision, Recall, F1-Score, AUC-ROC) on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5d9d5c9"
      },
      "source": [
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
        "values = [accuracy, precision, recall, f1, auc_roc]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=metrics, y=values)\n",
        "plt.title('Model Evaluation Metrics on Validation Set')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOL8m06qzrlgXHc7OwmwpgD"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}